{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of answers containing 'I don't know': 300\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "CSV_FILE = 'test_results_july3.csv'\n",
    "\n",
    "# Define the field names\n",
    "fieldnames = [\n",
    "    'section', 'dataset', 'embedder', 'chunking_detail', 'timestamp', 'extra_info', 'device', 'evalmodel', 'Prompt', 'ModelName',\n",
    "    'Temperature', 'TopK', 'SimilarityThresholdDocuments',\n",
    "    'SimilarityThresholdQuestions', 'runId', 'category',\n",
    "    'TFIDFScore', 'ResponseTime', 'answer_correctness',\n",
    "    'faithfulness', 'answer_similarity', 'answer_relevancy', 'context_precision',\n",
    "    'context_relevancy', 'context_recall', 'response_json'\n",
    "]\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "# df= df[(df['chunking_detail'] == 'no_RAG')]\n",
    "# Parse the 'response_json' to extract the 'answer' field\n",
    "def extract_answer(json_str):\n",
    "    try:\n",
    "        response = json.loads(json_str)\n",
    "        return response.get('answer', '')\n",
    "    except json.JSONDecodeError:\n",
    "        return ''\n",
    "\n",
    "# Create a new column with the extracted answers\n",
    "df['extracted_answer'] = df['response_json'].apply(extract_answer)\n",
    "\n",
    "# Log how many answers contain \"I don't know\"\n",
    "num_dont_know = df['extracted_answer'].str.contains(\"I don't know\", case=False).sum()\n",
    "print(f\"Number of answers containing 'I don't know': {num_dont_know}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ModelName chunking_detail  TFIDFScore  ResponseTime  \\\n",
      "0            gemma2:9b       1000_20_3    0.480896   2242.114147   \n",
      "1            gemma2:9b          no_RAG    0.382859   1656.865953   \n",
      "2   gpt-3.5-turbo-0125       1000_20_3    0.497467   3952.746252   \n",
      "3   gpt-3.5-turbo-0125          no_RAG    0.465772   1246.909274   \n",
      "4               gpt-4o       1000_20_3    0.524822   5148.209342   \n",
      "5               gpt-4o    assistantAPI    0.512130   9099.639243   \n",
      "6               gpt-4o          no_RAG    0.454131   2245.967796   \n",
      "7           llama3:70b       1000_20_3    0.510852   7446.358219   \n",
      "8           llama3:70b          no_RAG    0.446166   7594.727234   \n",
      "9            llama3:8b       1000_20_3    0.474095   1999.263052   \n",
      "10           llama3:8b          no_RAG    0.416392   1484.852913   \n",
      "11            phi3:14b       1000_20_3    0.459565   2679.640484   \n",
      "12            phi3:14b          no_RAG    0.395021   2987.052896   \n",
      "13           phi3:3.8b       1000_20_3    0.427965   2008.686746   \n",
      "14           phi3:3.8b          no_RAG    0.393362   1296.121826   \n",
      "\n",
      "    answer_similarity  answer_correctness  \n",
      "0            0.829606            0.580366  \n",
      "1            0.807397            0.514321  \n",
      "2            0.851005            0.578492  \n",
      "3            0.843942            0.531153  \n",
      "4            0.853642            0.588303  \n",
      "5            0.853174            0.582540  \n",
      "6            0.839658            0.539707  \n",
      "7            0.837902            0.576634  \n",
      "8            0.835126            0.522577  \n",
      "9            0.820752            0.562177  \n",
      "10           0.821871            0.482263  \n",
      "11           0.843779            0.564244  \n",
      "12           0.810432            0.502076  \n",
      "13           0.814322            0.542842  \n",
      "14           0.824878            0.507569  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "         \n",
    "CSV_FILE = 'test_results.csv'\n",
    "\n",
    "fieldnames = [\n",
    "    'section', 'dataset', 'embedder', 'chunking_detail', 'timestamp', 'extra_info', 'device', 'evalmodel', 'Prompt', 'ModelName',\n",
    "    'Temperature', 'TopK', 'SimilarityThresholdDocuments',\n",
    "    'SimilarityThresholdQuestions', 'runId', 'category',\n",
    "    'TFIDFScore', 'ResponseTime', 'answer_correctness',\n",
    "    'faithfulness', 'answer_similarity', 'answer_relevancy', 'context_precision',\n",
    "    'context_relevancy', 'context_recall', 'response_json'\n",
    "]\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(CSV_FILE, usecols=fieldnames)\n",
    "\n",
    "# Ensure numeric columns are indeed numeric\n",
    "numeric_cols = [\n",
    "    'TFIDFScore', 'ResponseTime', 'answer_similarity', 'answer_correctness'\n",
    "]\n",
    "\n",
    "# Convert the specified columns to numeric, coercing errors to NaN\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in numeric columns to avoid issues during aggregation\n",
    "df = df.dropna(subset=numeric_cols)\n",
    "\n",
    "# df_filtered = df[(df['section'] == 'General') & (df['chunking_detail'] != 'no_RAG')]\n",
    "df_filtered = df[(df['section'] == 'General')]\n",
    "\n",
    "# Group by both 'ModelName' and 'chunking_detail' and calculate the mean\n",
    "comparison_df = df_filtered.groupby(['ModelName', 'chunking_detail'])[numeric_cols].mean().reset_index()\n",
    "\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ModelName chunking_detail  TFIDFScore  ResponseTime  \\\n",
      "0            gemma2:9b       1000_20_3    0.484935   2192.673441   \n",
      "1            gemma2:9b          no_RAG    0.399836    982.750980   \n",
      "2   gpt-3.5-turbo-0125       1000_20_3    0.491482   1985.400037   \n",
      "3   gpt-3.5-turbo-0125    assistantAPI    0.511297   4805.140309   \n",
      "4               gpt-4o       1000_20_3    0.518271   3540.949103   \n",
      "5           llama3:70b       1000_20_3    0.501360   7725.311983   \n",
      "6           llama3:70b          no_RAG    0.434916   5722.910952   \n",
      "7            llama3:8b       1000_20_3    0.474585   2035.047739   \n",
      "8            llama3:8b          no_RAG    0.425080   1640.433754   \n",
      "9             phi3:14b       1000_20_3    0.462092   3119.280640   \n",
      "10           phi3:3.8b       1000_20_3    0.419408   2014.021480   \n",
      "11           phi3:3.8b          no_RAG    0.397382   1356.387053   \n",
      "\n",
      "    answer_similarity  answer_correctness  TFIDFScore_std  \\\n",
      "0            0.828361            0.591821        0.189566   \n",
      "1            0.789363            0.515883        0.179931   \n",
      "2            0.839123            0.546473        0.186394   \n",
      "3            0.847026            0.588743        0.162174   \n",
      "4            0.833099            0.545683        0.198994   \n",
      "5            0.832540            0.575639        0.175776   \n",
      "6            0.796265            0.510824        0.191686   \n",
      "7            0.825106            0.563945        0.164473   \n",
      "8            0.805413            0.462669        0.157290   \n",
      "9            0.837819            0.570464        0.151726   \n",
      "10           0.812287            0.535013        0.164464   \n",
      "11           0.822464            0.500143        0.131790   \n",
      "\n",
      "    answer_similarity_std  answer_correctness_std  TFIDFScore_rmse  \\\n",
      "0                0.141146                0.191170         0.189098   \n",
      "1                0.178297                0.164456         0.179496   \n",
      "2                0.117344                0.180984         0.185884   \n",
      "3                0.107479                0.170910         0.161780   \n",
      "4                0.127866                0.198126         0.198477   \n",
      "5                0.140451                0.190111         0.175344   \n",
      "6                0.214889                0.178213         0.191218   \n",
      "7                0.126931                0.172180         0.164068   \n",
      "8                0.179161                0.153446         0.156908   \n",
      "9                0.100232                0.154560         0.151348   \n",
      "10               0.140701                0.160344         0.164052   \n",
      "11               0.120686                0.130285         0.131468   \n",
      "\n",
      "    answer_similarity_rmse  answer_correctness_rmse  WeightedScore  \\\n",
      "0                 0.140798                 0.190698       0.635039   \n",
      "1                 0.177866                 0.164058       0.568361   \n",
      "2                 0.117023                 0.180488       0.625693   \n",
      "3                 0.107218                 0.170495       0.649022   \n",
      "4                 0.127534                 0.197612       0.632351   \n",
      "5                 0.140106                 0.189645       0.636513   \n",
      "6                 0.214365                 0.177778       0.580668   \n",
      "7                 0.126618                 0.171756       0.621212   \n",
      "8                 0.178725                 0.153073       0.564387   \n",
      "9                 0.099982                 0.154175       0.623458   \n",
      "10                0.140349                 0.159943       0.588902   \n",
      "11                0.120391                 0.129967       0.573329   \n",
      "\n",
      "    AverageDistribution  \n",
      "0              0.635039  \n",
      "1              0.568361  \n",
      "2              0.625693  \n",
      "3              0.649022  \n",
      "4              0.632351  \n",
      "5              0.636513  \n",
      "6              0.580668  \n",
      "7              0.621212  \n",
      "8              0.564387  \n",
      "9              0.623458  \n",
      "10             0.588902  \n",
      "11             0.573329  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_8451/3022748534.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['TFIDFScore_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['TFIDFScore'].transform('std')\n",
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_8451/3022748534.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['answer_similarity_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_similarity'].transform('std')\n",
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_8451/3022748534.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['answer_correctness_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_correctness'].transform('std')\n",
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_8451/3022748534.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['TFIDFScore_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['TFIDFScore'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n",
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_8451/3022748534.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['answer_similarity_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_similarity'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n",
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_8451/3022748534.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['answer_correctness_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_correctness'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CSV_FILE = 'test_results_july3.csv'\n",
    "\n",
    "fieldnames = [\n",
    "    'section', 'dataset', 'embedder', 'chunking_detail', 'timestamp', 'extra_info', 'device', 'evalmodel', 'Prompt', 'ModelName',\n",
    "    'Temperature', 'TopK', 'SimilarityThresholdDocuments',\n",
    "    'SimilarityThresholdQuestions', 'runId', 'category',\n",
    "    'TFIDFScore', 'ResponseTime', 'answer_correctness',\n",
    "    'faithfulness', 'answer_similarity', 'answer_relevancy', 'context_precision',\n",
    "    'context_relevancy', 'context_recall', 'response_json'\n",
    "]\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(CSV_FILE, usecols=fieldnames)\n",
    "\n",
    "# Ensure numeric columns are indeed numeric\n",
    "numeric_cols = [\n",
    "    'TFIDFScore', 'ResponseTime', 'answer_similarity', 'answer_correctness'\n",
    "]\n",
    "\n",
    "# Convert the specified columns to numeric, coercing errors to NaN\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in numeric columns to avoid issues during aggregation\n",
    "df = df.dropna(subset=numeric_cols)\n",
    "\n",
    "# Filter the DataFrame for 'General' section\n",
    "df_filtered = df[df['section'] == 'General']\n",
    "\n",
    "# Calculate mean, standard deviation, and RMSE for the specified metrics\n",
    "df_filtered['TFIDFScore_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['TFIDFScore'].transform('std')\n",
    "df_filtered['answer_similarity_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_similarity'].transform('std')\n",
    "df_filtered['answer_correctness_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_correctness'].transform('std')\n",
    "\n",
    "df_filtered['TFIDFScore_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['TFIDFScore'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n",
    "df_filtered['answer_similarity_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_similarity'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n",
    "df_filtered['answer_correctness_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_correctness'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n",
    "\n",
    "comparison_df = df_filtered.groupby(['ModelName', 'chunking_detail'])[numeric_cols + [\n",
    "    'TFIDFScore_std', 'answer_similarity_std', 'answer_correctness_std',\n",
    "    'TFIDFScore_rmse', 'answer_similarity_rmse', 'answer_correctness_rmse'\n",
    "]].mean().reset_index()\n",
    "\n",
    "# Calculate weighted score and average distribution of the three metrics\n",
    "comparison_df['WeightedScore'] = comparison_df.apply(\n",
    "    lambda row: (row['TFIDFScore'] + row['answer_similarity'] + row['answer_correctness']) / 3, axis=1\n",
    ")\n",
    "comparison_df['AverageDistribution'] = comparison_df[['TFIDFScore', 'answer_similarity', 'answer_correctness']].mean(axis=1)\n",
    "\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CSV_FILE = 'test_results.csv'\n",
    "\n",
    "fieldnames = [\n",
    "    'section', 'dataset', 'embedder', 'chunking_detail', 'timestamp', 'extra_info', 'device', 'evalmodel', 'Prompt', 'ModelName',\n",
    "    'Temperature', 'TopK', 'SimilarityThresholdDocuments',\n",
    "    'SimilarityThresholdQuestions', 'runId', 'category',\n",
    "    'TFIDFScore', 'ResponseTime', 'answer_correctness',\n",
    "    'faithfulness', 'answer_similarity', 'answer_relevancy', 'context_precision',\n",
    "    'context_relevancy', 'context_recall', 'response_json'\n",
    "]\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(CSV_FILE, usecols=fieldnames)\n",
    "\n",
    "# Update the chunking_detail for the specified runIds\n",
    "df.loc[df['runId'] == 1721458822, 'chunking_detail'] = 'assistantAPI'\n",
    "df.loc[df['runId'] == 1721494959, 'chunking_detail'] = 'no_RAG'\n",
    "\n",
    "# Save the modified DataFrame back to the CSV file\n",
    "df.to_csv(CSV_FILE, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ModelName chunking_detail       runId  TFIDFScore  ResponseTime  \\\n",
      "0            gemma2:9b       1000_20_3  1720708303    0.425435   1759.735881   \n",
      "1            gemma2:9b          no_RAG  1720649180    0.238822   1340.057940   \n",
      "2   gpt-3.5-turbo-0125       1000_20_3  1720675512    0.435688   1806.864813   \n",
      "3   gpt-3.5-turbo-0125       1000_20_3  1720774209    0.396763   2855.950499   \n",
      "4   gpt-3.5-turbo-0125          no_RAG  1720802607    0.304090   1078.918457   \n",
      "5               gpt-4o       1000_20_3  1720690030    0.448099   3730.162665   \n",
      "6               gpt-4o    assistantAPI  1720826113    0.460103   7660.685264   \n",
      "7               gpt-4o          no_RAG  1720817390    0.275471   1699.062331   \n",
      "8          gpt-4o-mini       1000_20_3  1721448144    0.430777   2487.343407   \n",
      "9          gpt-4o-mini    assistantAPI  1721458822    0.450224   9018.972574   \n",
      "10         gpt-4o-mini    assistantAPI  1721605211    0.449528   7280.107872   \n",
      "11         gpt-4o-mini          no_RAG  1721494959    0.274126   1722.089624   \n",
      "12          llama3:70b       1000_20_3  1720723303    0.431367   6088.770718   \n",
      "13          llama3:70b       1000_20_3  1721087863    0.425120   5869.217703   \n",
      "14          llama3:70b          no_RAG  1720653618    0.306420   6552.860618   \n",
      "15           llama3:8b       1000_20_3  1720740381    0.397883   1835.107560   \n",
      "16           llama3:8b          no_RAG  1720659848    0.293889   1320.419772   \n",
      "17            phi3:14b       1000_20_3  1721170409    0.385674   2271.162409   \n",
      "18            phi3:14b          no_RAG  1720643627    0.269639   2306.156598   \n",
      "19           phi3:3.8b       1000_20_3  1720756458    0.367150   1681.137643   \n",
      "20           phi3:3.8b          no_RAG  1720664620    0.246389   1117.843514   \n",
      "\n",
      "    answer_similarity  answer_correctness  TFIDFScore_std  \\\n",
      "0            0.729131            0.556991        0.183975   \n",
      "1            0.644061            0.313224        0.158583   \n",
      "2            0.728217            0.524794        0.179236   \n",
      "3            0.700384            0.512577        0.179236   \n",
      "4            0.656351            0.360535        0.165677   \n",
      "5            0.718300            0.538967        0.196492   \n",
      "6            0.741187            0.582453        0.184931   \n",
      "7            0.637601            0.339380        0.182231   \n",
      "8            0.749396            0.556098        0.167526   \n",
      "9            0.757957            0.550186        0.185341   \n",
      "10           0.745434            0.539811        0.185341   \n",
      "11           0.661298            0.335155        0.177858   \n",
      "12           0.721890            0.531042        0.183058   \n",
      "13           0.726273            0.512170        0.183058   \n",
      "14           0.656387            0.343786        0.177436   \n",
      "15           0.691281            0.471877        0.173829   \n",
      "16           0.639316            0.282447        0.174458   \n",
      "17           0.674022            0.482278        0.175180   \n",
      "18           0.605535            0.299668        0.144503   \n",
      "19           0.702123            0.486190        0.145831   \n",
      "20           0.617356            0.287667        0.139315   \n",
      "\n",
      "    answer_similarity_std  answer_correctness_std  TFIDFScore_rmse  \\\n",
      "0                0.158811                0.250285         0.181920   \n",
      "1                0.172687                0.199639         0.156811   \n",
      "2                0.149245                0.205013         0.178237   \n",
      "3                0.149245                0.205013         0.178237   \n",
      "4                0.184419                0.220423         0.163826   \n",
      "5                0.148125                0.233849         0.194193   \n",
      "6                0.149896                0.186408         0.182865   \n",
      "7                0.182635                0.185573         0.180149   \n",
      "8                0.136991                0.201543         0.165654   \n",
      "9                0.140093                0.199426         0.184273   \n",
      "10               0.140093                0.199426         0.184273   \n",
      "11               0.179020                0.204102         0.175871   \n",
      "12               0.137728                0.242490         0.182038   \n",
      "13               0.137728                0.242490         0.182038   \n",
      "14               0.169689                0.196641         0.175408   \n",
      "15               0.178936                0.230885         0.171886   \n",
      "16               0.183536                0.179143         0.172508   \n",
      "17               0.182326                0.202165         0.173222   \n",
      "18               0.168613                0.180675         0.142888   \n",
      "19               0.145833                0.207256         0.144164   \n",
      "20               0.195254                0.167083         0.137723   \n",
      "\n",
      "    answer_similarity_rmse  answer_correctness_rmse  AverageScore  AverageStd  \\\n",
      "0                 0.157036                 0.247489      0.570519    0.197691   \n",
      "1                 0.170758                 0.197409      0.398702    0.176970   \n",
      "2                 0.148414                 0.203871      0.562900    0.177831   \n",
      "3                 0.148414                 0.203871      0.536574    0.177831   \n",
      "4                 0.182358                 0.217960      0.440325    0.190173   \n",
      "5                 0.146393                 0.231114      0.568455    0.192822   \n",
      "6                 0.148222                 0.184325      0.594581    0.173745   \n",
      "7                 0.180548                 0.183452      0.417484    0.183480   \n",
      "8                 0.135460                 0.199291      0.578757    0.168687   \n",
      "9                 0.139285                 0.198277      0.586122    0.174953   \n",
      "10                0.139285                 0.198277      0.578258    0.174953   \n",
      "11                0.177019                 0.201821      0.423526    0.186993   \n",
      "12                0.136961                 0.241139      0.561433    0.187759   \n",
      "13                0.136961                 0.241139      0.554521    0.187759   \n",
      "14                0.167749                 0.194394      0.435531    0.181255   \n",
      "15                0.176936                 0.228305      0.520347    0.194550   \n",
      "16                0.181485                 0.177142      0.405217    0.179046   \n",
      "17                0.180289                 0.199906      0.513991    0.186557   \n",
      "18                0.166729                 0.178656      0.391614    0.164597   \n",
      "19                0.144167                 0.204888      0.518488    0.166307   \n",
      "20                0.193022                 0.165174      0.383804    0.167217   \n",
      "\n",
      "    AverageRMSE  \n",
      "0      0.195482  \n",
      "1      0.174992  \n",
      "2      0.176841  \n",
      "3      0.176841  \n",
      "4      0.188048  \n",
      "5      0.190567  \n",
      "6      0.171804  \n",
      "7      0.181383  \n",
      "8      0.166802  \n",
      "9      0.173945  \n",
      "10     0.173945  \n",
      "11     0.184904  \n",
      "12     0.186713  \n",
      "13     0.186713  \n",
      "14     0.179184  \n",
      "15     0.192376  \n",
      "16     0.177045  \n",
      "17     0.184473  \n",
      "18     0.162758  \n",
      "19     0.164406  \n",
      "20     0.165306  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_4272/704160980.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['TFIDFScore_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['TFIDFScore'].transform('std')\n",
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_4272/704160980.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['answer_similarity_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_similarity'].transform('std')\n",
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_4272/704160980.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['answer_correctness_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_correctness'].transform('std')\n",
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_4272/704160980.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['TFIDFScore_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['TFIDFScore'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n",
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_4272/704160980.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['answer_similarity_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_similarity'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n",
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_4272/704160980.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['answer_correctness_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_correctness'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CSV_FILE = 'test_results.csv'\n",
    "\n",
    "fieldnames = [\n",
    "    'section', 'dataset', 'embedder', 'chunking_detail', 'timestamp', 'extra_info', 'device', 'evalmodel', 'Prompt', 'ModelName',\n",
    "    'Temperature', 'TopK', 'SimilarityThresholdDocuments',\n",
    "    'SimilarityThresholdQuestions', 'runId', 'category',\n",
    "    'TFIDFScore', 'ResponseTime', 'answer_correctness',\n",
    "    'faithfulness', 'answer_similarity', 'answer_relevancy', 'context_precision',\n",
    "    'context_relevancy', 'context_recall', 'response_json'\n",
    "]\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(CSV_FILE, usecols=fieldnames)\n",
    "\n",
    "# Ensure numeric columns are indeed numeric\n",
    "numeric_cols = [\n",
    "    'TFIDFScore', 'ResponseTime', 'answer_similarity', 'answer_correctness'\n",
    "]\n",
    "\n",
    "# Convert the specified columns to numeric, coercing errors to NaN\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "# Assuming df and numeric_cols are defined\n",
    "df = df.dropna(subset=numeric_cols)\n",
    "\n",
    "df_filtered = df[(df['section'] != 'General')]\n",
    "\n",
    "# Calculate mean, standard deviation, and RMSE for the specified metrics\n",
    "df_filtered['TFIDFScore_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['TFIDFScore'].transform('std')\n",
    "df_filtered['answer_similarity_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_similarity'].transform('std')\n",
    "df_filtered['answer_correctness_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_correctness'].transform('std')\n",
    "\n",
    "df_filtered['TFIDFScore_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['TFIDFScore'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n",
    "df_filtered['answer_similarity_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_similarity'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n",
    "df_filtered['answer_correctness_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_correctness'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n",
    "\n",
    "comparison_df = df_filtered.groupby(['ModelName', 'chunking_detail', 'runId'])[numeric_cols + [\n",
    "    'TFIDFScore_std', 'answer_similarity_std', 'answer_correctness_std',\n",
    "    'TFIDFScore_rmse', 'answer_similarity_rmse', 'answer_correctness_rmse'\n",
    "]].mean().reset_index()\n",
    "\n",
    "# Calculate weighted score and average distribution of the three metrics\n",
    "comparison_df['AverageScore'] = comparison_df.apply(\n",
    "    lambda row: (row['TFIDFScore'] + row['answer_similarity'] + row['answer_correctness']) / 3, axis=1\n",
    ")\n",
    "comparison_df['AverageStd'] = comparison_df[['TFIDFScore_std', 'answer_similarity_std', 'answer_correctness_std']].mean(axis=1)\n",
    "comparison_df['AverageRMSE'] = comparison_df[['TFIDFScore_rmse', 'answer_similarity_rmse', 'answer_correctness_rmse']].mean(axis=1)\n",
    "\n",
    "print(comparison_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  chunking_detail  TFIDFScore  ResponseTime  answer_similarity  \\\n",
      "0       1000_20_3    0.421082   3907.945034           0.719911   \n",
      "1          no_RAG    0.276106   2133.931742           0.639760   \n",
      "\n",
      "   answer_correctness  TFIDFScore_std  answer_similarity_std  \\\n",
      "0            0.525399        0.177606               0.150208   \n",
      "1            0.320204        0.164997               0.179456   \n",
      "\n",
      "   answer_correctness_std  TFIDFScore_rmse  answer_similarity_rmse  \\\n",
      "0                0.216941         0.176288                0.149050   \n",
      "1                0.191732         0.163137                0.177434   \n",
      "\n",
      "   answer_correctness_rmse  AverageScore  AverageStd  AverageRMSE  \n",
      "0                 0.215302      0.555464    0.181585     0.180213  \n",
      "1                 0.189572      0.412023    0.178728     0.176714  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_4272/1656284832.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['chunking_detail'] = df_filtered['chunking_detail'].replace('assistantAPI', '1000_20_3')\n",
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_4272/1656284832.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['TFIDFScore_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['TFIDFScore'].transform('std')\n",
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_4272/1656284832.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['answer_similarity_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_similarity'].transform('std')\n",
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_4272/1656284832.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['answer_correctness_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_correctness'].transform('std')\n",
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_4272/1656284832.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['TFIDFScore_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['TFIDFScore'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n",
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_4272/1656284832.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['answer_similarity_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_similarity'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n",
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_4272/1656284832.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['answer_correctness_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_correctness'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CSV_FILE = 'test_results.csv'\n",
    "\n",
    "fieldnames = [\n",
    "    'section', 'dataset', 'embedder', 'chunking_detail', 'timestamp', 'extra_info', 'device', 'evalmodel', 'Prompt', 'ModelName',\n",
    "    'Temperature', 'TopK', 'SimilarityThresholdDocuments',\n",
    "    'SimilarityThresholdQuestions', 'runId', 'category',\n",
    "    'TFIDFScore', 'ResponseTime', 'answer_correctness',\n",
    "    'faithfulness', 'answer_similarity', 'answer_relevancy', 'context_precision',\n",
    "    'context_relevancy', 'context_recall', 'response_json'\n",
    "]\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(CSV_FILE, usecols=fieldnames)\n",
    "\n",
    "# Ensure numeric columns are indeed numeric\n",
    "numeric_cols = [\n",
    "    'TFIDFScore', 'ResponseTime', 'answer_similarity', 'answer_correctness'\n",
    "]\n",
    "\n",
    "# Convert the specified columns to numeric, coercing errors to NaN\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in numeric columns\n",
    "df = df.dropna(subset=numeric_cols)\n",
    "\n",
    "# Filter out the section 'General'\n",
    "df_filtered = df[df['section'] != 'General']\n",
    "\n",
    "# Replace 'assistantAPI' with '1000_20_3' in chunking_detail\n",
    "df_filtered['chunking_detail'] = df_filtered['chunking_detail'].replace('assistantAPI', '1000_20_3')\n",
    "\n",
    "# Calculate mean, standard deviation, and RMSE for the specified metrics\n",
    "df_filtered['TFIDFScore_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['TFIDFScore'].transform('std')\n",
    "df_filtered['answer_similarity_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_similarity'].transform('std')\n",
    "df_filtered['answer_correctness_std'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_correctness'].transform('std')\n",
    "\n",
    "df_filtered['TFIDFScore_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['TFIDFScore'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n",
    "df_filtered['answer_similarity_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_similarity'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n",
    "df_filtered['answer_correctness_rmse'] = df_filtered.groupby(['ModelName', 'chunking_detail'])['answer_correctness'].transform(lambda x: np.sqrt(np.mean((x - x.mean())**2)))\n",
    "\n",
    "# Group by chunking_detail to compare \"no_RAG\" vs. the rest\n",
    "comparison_df = df_filtered.groupby(['chunking_detail'])[numeric_cols + [\n",
    "    'TFIDFScore_std', 'answer_similarity_std', 'answer_correctness_std',\n",
    "    'TFIDFScore_rmse', 'answer_similarity_rmse', 'answer_correctness_rmse'\n",
    "]].mean().reset_index()\n",
    "\n",
    "# Calculate weighted score and average distribution of the three metrics\n",
    "comparison_df['AverageScore'] = comparison_df.apply(\n",
    "    lambda row: (row['TFIDFScore'] + row['answer_similarity'] + row['answer_correctness']) / 3, axis=1\n",
    ")\n",
    "comparison_df['AverageStd'] = comparison_df[['TFIDFScore_std', 'answer_similarity_std', 'answer_correctness_std']].mean(axis=1)\n",
    "comparison_df['AverageRMSE'] = comparison_df[['TFIDFScore_rmse', 'answer_similarity_rmse', 'answer_correctness_rmse']].mean(axis=1)\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ModelName chunking_detail  TFIDFScore_before  ResponseTime_before  \\\n",
      "0           gemma2:9b       1000_20_3           0.469152          1734.553026   \n",
      "1  gpt-3.5-turbo-0125       1000_20_3           0.493496          1580.045041   \n",
      "2  gpt-3.5-turbo-0125    assistantAPI           0.501313          4785.197028   \n",
      "3              gpt-4o       1000_20_3           0.507940          3475.761402   \n",
      "4         gpt-4o-mini       1000_20_3           0.532322          2044.048836   \n",
      "5          llama3:70b       1000_20_3           0.466509          5813.427644   \n",
      "6           llama3:8b       1000_20_3           0.440145          1757.937967   \n",
      "7            phi3:14b       1000_20_3           0.456959          3155.549485   \n",
      "8           phi3:3.8b       1000_20_3           0.431111          1807.065723   \n",
      "\n",
      "   answer_similarity_before  answer_correctness_before  WeightedScore_before  \\\n",
      "0                  0.781595                   0.574824              0.608524   \n",
      "1                  0.830967                   0.577408              0.633957   \n",
      "2                  0.827358                   0.576930              0.635200   \n",
      "3                  0.813328                   0.543519              0.621596   \n",
      "4                  0.845657                   0.600101              0.659360   \n",
      "5                  0.796804                   0.528876              0.597396   \n",
      "6                  0.797369                   0.521901              0.586472   \n",
      "7                  0.805123                   0.537635              0.599906   \n",
      "8                  0.774000                   0.523314              0.576142   \n",
      "\n",
      "   TFIDFScore_after  ResponseTime_after  answer_similarity_after  \\\n",
      "0          0.465286         1723.961815                 0.774785   \n",
      "1          0.493640         1580.392899                 0.831212   \n",
      "2          0.501313         4785.197028                 0.827358   \n",
      "3          0.498462         3395.052149                 0.791211   \n",
      "4          0.529251         2032.269068                 0.841733   \n",
      "5          0.438448         5377.369360                 0.722478   \n",
      "6          0.399101         1558.424487                 0.702729   \n",
      "7          0.448998         3090.287830                 0.784996   \n",
      "8          0.314534         1164.291710                 0.554972   \n",
      "\n",
      "   answer_correctness_after  WeightedScore_after  idk_count  \n",
      "0                  0.570534             0.603535          2  \n",
      "1                  0.577408             0.634087          0  \n",
      "2                  0.576930             0.635200          0  \n",
      "3                  0.535800             0.608491          9  \n",
      "4                  0.598015             0.656333          1  \n",
      "5                  0.506053             0.555660         28  \n",
      "6                  0.492314             0.531381         33  \n",
      "7                  0.529385             0.587793          8  \n",
      "8                  0.376676             0.415394         74  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x2/3kx_8_012rjdwr8pb9vgxmcw0000gn/T/ipykernel_4272/429061854.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['idk_count'] = df_filtered['extracted_answer'].str.contains(\"I don't know\", case=False).astype(int)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json \n",
    "\n",
    "CSV_FILE = 'test_results_july3.csv'\n",
    "\n",
    "fieldnames = [\n",
    "    'section', 'dataset', 'embedder', 'chunking_detail', 'timestamp', 'extra_info', 'device', 'evalmodel', 'Prompt', 'ModelName',\n",
    "    'Temperature', 'TopK', 'SimilarityThresholdDocuments',\n",
    "    'SimilarityThresholdQuestions', 'runId', 'category',\n",
    "    'TFIDFScore', 'ResponseTime', 'answer_correctness',\n",
    "    'faithfulness', 'answer_similarity', 'answer_relevancy', 'context_precision',\n",
    "    'context_relevancy', 'context_recall', 'response_json'\n",
    "]\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(CSV_FILE, usecols=fieldnames)\n",
    "\n",
    "# Ensure numeric columns are indeed numeric\n",
    "numeric_cols = [\n",
    "    'TFIDFScore', 'ResponseTime', 'answer_similarity', 'answer_correctness'\n",
    "]\n",
    "\n",
    "# Convert the specified columns to numeric, coercing errors to NaN\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Parse the 'response_json' to extract the 'answer' field\n",
    "def extract_answer(json_str):\n",
    "    try:\n",
    "        response = json.loads(json_str)\n",
    "        return response.get('answer', '')\n",
    "    except json.JSONDecodeError:\n",
    "        return ''\n",
    "\n",
    "# Create a new column with the extracted answers\n",
    "df['extracted_answer'] = df['response_json'].apply(extract_answer)\n",
    "\n",
    "# Filter the DataFrame for 'General' section\n",
    "df_filtered = df[(df['chunking_detail'] != 'no_RAG')]\n",
    "\n",
    "# Group by ModelName and chunking_detail and calculate mean scores before setting to 0\n",
    "before_scores = df_filtered.groupby(['ModelName', 'chunking_detail'])[numeric_cols].mean().reset_index()\n",
    "\n",
    "# Count the number of \"I don't know\" responses\n",
    "df_filtered['idk_count'] = df_filtered['extracted_answer'].str.contains(\"I don't know\", case=False).astype(int)\n",
    "idk_count_df = df_filtered.groupby(['ModelName', 'chunking_detail'])['idk_count'].sum().reset_index()\n",
    "\n",
    "# Set scores to 0 if the answer contains \"I don't know\"\n",
    "condition = df_filtered['extracted_answer'].str.contains(\"I don't know\", case=False)\n",
    "df_filtered.loc[condition, numeric_cols] = 0\n",
    "\n",
    "# Drop rows with NaN values in numeric columns to avoid issues during aggregation\n",
    "df_filtered = df_filtered.dropna(subset=numeric_cols)\n",
    "\n",
    "# Group by ModelName and chunking_detail and calculate mean scores after setting to 0\n",
    "after_scores = df_filtered.groupby(['ModelName', 'chunking_detail'])[numeric_cols].mean().reset_index()\n",
    "\n",
    "# Calculate weighted score for before and after\n",
    "before_scores['WeightedScore'] = before_scores.apply(\n",
    "    lambda row: (row['TFIDFScore'] + row['answer_similarity'] + row['answer_correctness']) / 3, axis=1\n",
    ")\n",
    "after_scores['WeightedScore'] = after_scores.apply(\n",
    "    lambda row: (row['TFIDFScore'] + row['answer_similarity'] + row['answer_correctness']) / 3, axis=1\n",
    ")\n",
    "\n",
    "# Merge idk_count with before and after scores\n",
    "comparison_df = before_scores.merge(after_scores, on=['ModelName', 'chunking_detail'], suffixes=('_before', '_after'))\n",
    "comparison_df = comparison_df.merge(idk_count_df, on=['ModelName', 'chunking_detail'])\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(comparison_df)\n",
    "\n",
    "# The resulting DataFrame will have the counts of \"I don't know\" responses and the before and after scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
