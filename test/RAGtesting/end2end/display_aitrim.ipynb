{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ModelName chunking_detail  TFIDFScore  ResponseTime  answer_similarity  \\\n",
      "0  llama3:70b       1000_20_3    0.484811   7326.361898           0.837853   \n",
      "\n",
      "   context_relevancy  context_recall  context_precision  \n",
      "0           0.491546        0.675989           0.933007  \n",
      "    ModelName chunking_detail  TFIDFScore  ResponseTime  answer_similarity  \\\n",
      "0  llama3:70b       1000_20_3    0.494658   7186.205086           0.816732   \n",
      "\n",
      "   context_relevancy  context_recall  context_precision  \n",
      "0           0.205011        0.594614           0.844758  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CSV_FILE = 'test_results_ai_trim.csv'\n",
    "CSV_FILE1 = 'test_results.csv'\n",
    "\n",
    "fieldnames = [\n",
    "    'section', 'dataset', 'embedder', 'chunking_detail', 'timestamp', 'extra_info', 'device', 'evalmodel', 'Prompt', 'ModelName',\n",
    "    'Temperature', 'TopK', 'SimilarityThresholdDocuments',\n",
    "    'SimilarityThresholdQuestions', 'runId', 'category',\n",
    "    'TFIDFScore', 'ResponseTime', 'answer_correctness',\n",
    "    'faithfulness', 'answer_similarity', 'answer_relevancy', 'context_precision',\n",
    "    'context_relevancy', 'context_recall', 'response_json'\n",
    "]\n",
    "\n",
    "# Define numeric columns\n",
    "numeric_cols = [\n",
    "    'TFIDFScore', 'ResponseTime', 'answer_similarity', 'context_relevancy', 'context_recall', 'context_precision'\n",
    "]\n",
    "\n",
    "# Function to load and process the CSV file\n",
    "def load_and_process_csv(file_path):\n",
    "    df = pd.read_csv(file_path, usecols=fieldnames)\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    df = df.dropna(subset=numeric_cols)\n",
    "    return df\n",
    "\n",
    "# Load and process the first CSV file\n",
    "df = load_and_process_csv(CSV_FILE)\n",
    "\n",
    "# Filter and aggregate the first DataFrame\n",
    "df_filtered = df[(df['section'] == 'General')]\n",
    "comparison_df = df_filtered.groupby(['ModelName', 'chunking_detail'])[numeric_cols].mean().reset_index()\n",
    "print(comparison_df)\n",
    "\n",
    "# Load and process the second CSV file\n",
    "df1 = load_and_process_csv(CSV_FILE1)\n",
    "\n",
    "# Filter and aggregate the second DataFrame\n",
    "df1_filtered = df1[(df1['ModelName'] == 'llama3:70b') & (df1['chunking_detail'] == '1000_20_3')]\n",
    "comparison_df1 = df1_filtered.groupby(['ModelName', 'chunking_detail'])[numeric_cols].mean().reset_index()\n",
    "\n",
    "print(comparison_df1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
